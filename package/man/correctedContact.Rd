\name{correctedContact}
\alias{correctedContact}

\title{Iterative correction of Hi-C counts}

\description{Perform iterative correction on counts for Hi-C interactions to correct for biases between fragments.}

\usage{
correctedContact(data, iterations=50, exclude.local=1, ignore.low=0.02, 
    winsor.high=0.02, average=TRUE, dispersion=0.05)
}

\arguments{
	\item{data}{a \code{DIList} object produced by \code{\link{squareCounts}}}
	\item{iterations}{an integer scalar specifying the number of correction iterations}
	\item{exclude.local}{an integer scalar, indicating the distance off the diagonal under which bin pairs are excluded}
	\item{ignore.low}{a numeric scalar, indicating the proportion of low-abundance bins to ignore}
	\item{winsor.high}{a numeric scalar indicating the proportion of high-abundance bin pairs to winsorize}
	\item{average}{a logical scalar specifying whether counts should be averaged across libraries}
	\item{dispersion}{a numeric scalar for use in computing the average count in \code{\link{mglmOneGroup}}}
}

\value{
A list with several components.
\describe{	
	\item{\code{truth}:}{a numeric vector containing the true interaction probabilities for each bin pair}
	\item{\code{bias}:}{a numeric vector of biases for all bins}
    \item{\code{max}:}{a numeric vector containing the maximum fold-change change in biases at each iteration}
}
If \code{average=FALSE}, each component is a numeric matrix instead.
Each column of the matrix contains the specified information for each library in \code{data}.
}

\details{
This function implements the iterative correction procedure described by Imakaev \emph{et al.} in their 2012 paper. 
Briefly, this aims to factorize the count for each bin pair into the bias for the anchor bin, the bias for the target bin and the true interaction probability. 
The probability sums to 1 across all bin pairs for a given bin. 
The bias represents the ease of sequencing/mapping/other for that genomic region.

The \code{data} argument should be generated by taking the output of \code{\link{squareCounts}} after setting \code{filter=1}. 
Filtering should be avoided as counts in low-abundance bin pairs may be informative upon summation for each bin.
For example, a large count sum for a bin may be formed from many bin pairs with low counts.
Removal of those bin pairs would result in the loss of per-bin information.

Some robustness is provided by winsorizing out strong interactions with \code{winsor.high} to ensure that they do not overly influence the computed biases.
Low-abundance bins can also be removed with \code{ignore.low} to avoid instability during correction, though this will result in \code{NA} values in the output.

Local bin pairs can be excluded as these are typically irrelevant to long-range interactions. 
They are also typically very high-abundance and may have excessive weight during correction, if not removed. 
This can be done by removing all bin pairs where the difference between the anchor and target indices is less than \code{exclude.local}.

For \code{average=TRUE}, if multiple libraries are used to generate \code{data}, an average count will be computed for each bin pairs across all libraries using \code{\link{mglmOneGroup}} with the specified \code{dispersion}.
The average count will then be used for correction.
Otherwise, correction will be performed on the counts for each library separately.

The maximum step size in the output can be used as a measure of convergence. 
Ideally, the step size should approach 1 as iterations pass. 
This indicates that the correction procedure is converging to a single solution, as the maximum change to the computed biases is decreasing.

% True signals are continuous variables and have limited use in count-based statistical frameworks.
% You need to compute the bias for each one to get the offset.
}

\examples{
# Dummying up some data.
set.seed(3423746)
npts <- 100
npairs <- 5000
nlibs <- 4
anchors <- sample(npts, npairs, replace=TRUE)
targets <- sample(npts, npairs, replace=TRUE)
data <- DIList(counts=matrix(rpois(npairs*nlibs, runif(npairs, 10, 100)), nrow=npairs),
	totals=runif(nlibs, 1e6, 2e6), anchors=pmax(anchors, targets), targets=pmin(anchors, targets),
	regions=GRanges("chrA", IRanges(1:npts, 1:npts)))

# Correcting.
stuff <- correctedContact(data)
head(stuff$truth)
head(stuff$bias)
plot(stuff$max)

# Different behaviour with average=FALSE.
stuff <- correctedContact(data, average=FALSE)
head(stuff$truth)
head(stuff$bias)
head(stuff$max)
}

\author{Aaron Lun}

\seealso{
\code{\link{squareCounts}}, 
\code{\link{mglmOneGroup}}
}

\references{
Imakaev M et al. (2012). Iterative correction of Hi-C data reveals hallmarks of chromosome organization. \emph{Nat. Methods} 9, 999-1003.
}

\keyword{normalization}
